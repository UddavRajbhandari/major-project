{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:21.047190Z",
     "iopub.status.busy": "2025-07-23T13:31:21.046579Z",
     "iopub.status.idle": "2025-07-23T13:31:22.335474Z",
     "shell.execute_reply": "2025-07-23T13:31:22.334751Z",
     "shell.execute_reply.started": "2025-07-23T13:31:21.047153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5577, 4)\n",
      "Test shape: (1450, 4)\n",
      "\n",
      "Sample data train:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label_Binary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label_Multiclass",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e3a98943-65bf-4058-9cc4-fea0577efb31",
       "rows": [
        [
         "0",
         "visewu",
         "‡§≠‡•Ç‡§ï‡§®‡•á ‡§ï‡•Ç‡§ï‡•Ç‡§∞ ‡§≤‡•á ‡§ï‡§π‡•Ä‡§≤‡•á ‡§ü‡•ã‡§ï‡§¶‡•à‡§® ‡§≠‡§®‡•ç‡§õ ‡§π‡•ã ‡§∞‡•à‡§õ ‡§∏‡§æ‡§≤‡§æ ‡§ß‡•ã‡§§‡•Ä ‡§§‡•Ä‡§Æ‡•Ä ‡§π‡§∞‡•Ç ‡§≤‡§æ‡§à ‡§ï‡•á‡§ï‡•ã ‡§Ö‡§ú‡§æ‡§¶‡•Ä ‡§ú‡§æ‡§π‡•Ä‡§Ø‡•ã",
         "OFF",
         "OR"
        ],
        [
         "1",
         "hgpmyz",
         "‡§§‡•á‡§∞‡•Ä ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§™‡§∏‡§≤ ‡§Æ‡•Ç‡§ú‡•Ä ‡§ï‡•Ç‡§ï‡•Ç‡§∞‡§ï‡•ã ‡§Æ‡•Ç‡§§ ‡§ñ‡§æ‡§è‡§∏‡•Ä ‡§ú‡•á ‡§™‡§®‡•Ä ‡§∏‡•Ç‡§®‡•ç‡§õ ‡§ã‡§§‡•Å‡§ú‡§ø‡§§‡§ï‡•ã ‡§ú‡§æ‡§Å‡§†‡§≤‡•á ‡§ú‡§æ ‡§ã‡§§‡•Å‡§ú‡§ø‡§§‡§ï‡•ã ‡§ù‡•ã‡§≤ ‡§ñ‡§æ‡§®",
         "OFF",
         "OO"
        ],
        [
         "2",
         "pwqyku",
         "thukka ta machikne valu kun level ko hosh dekhirax ta ani",
         "OFF",
         "OO"
        ],
        [
         "3",
         "voaytw",
         "‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Ö‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Æ‡•Ç‡§ú‡•Ä‡§π‡§∞‡•ç‡§≤‡§æ‡§à ‡§†‡•Ç‡§ä‡§â‡§â‡§≤‡•ã ‡§Æ‡•Ç‡§ú‡•Ä ‡§≠‡§®‡•ç‡§® ‡§ö‡§æ‡§®‡•ç‡§õ‡•Ç ‡§ß‡§®‡•ç‡§Ø‡§¨‡§æ‡§§‡•ç",
         "OFF",
         "OO"
        ],
        [
         "4",
         "mozgzm",
         "‡§ó‡§æ‡§à‡§≤‡§æ‡§à ‡§ó‡§ß‡§æ ‡§≠‡§®‡•á‡§∞ ‡§¨‡•Ä‡§∞‡§æ‡•á‡§ß ‡§ó‡§∞‡•á‡§ï‡§æ‡•á ‡§õ‡•à‡§® ‡§π‡§æ‡•á‡§≤‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§∞‡•á",
         "NOFF",
         "NO"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label_Binary</th>\n",
       "      <th>Label_Multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visewu</td>\n",
       "      <td>‡§≠‡•Ç‡§ï‡§®‡•á ‡§ï‡•Ç‡§ï‡•Ç‡§∞ ‡§≤‡•á ‡§ï‡§π‡•Ä‡§≤‡•á ‡§ü‡•ã‡§ï‡§¶‡•à‡§® ‡§≠‡§®‡•ç‡§õ ‡§π‡•ã ‡§∞‡•à‡§õ ‡§∏‡§æ‡§≤‡§æ ‡§ß...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hgpmyz</td>\n",
       "      <td>‡§§‡•á‡§∞‡•Ä ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§™‡§∏‡§≤ ‡§Æ‡•Ç‡§ú‡•Ä ‡§ï‡•Ç‡§ï‡•Ç‡§∞‡§ï‡•ã ‡§Æ‡•Ç‡§§ ‡§ñ‡§æ‡§è‡§∏‡•Ä ‡§ú‡•á ‡§™‡§®‡•Ä ‡§∏...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pwqyku</td>\n",
       "      <td>thukka ta machikne valu kun level ko hosh dekh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voaytw</td>\n",
       "      <td>‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Ö‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Æ‡•Ç‡§ú‡•Ä‡§π‡§∞‡•ç‡§≤‡§æ‡§à ‡§†‡•Ç‡§ä‡§â‡§â‡§≤‡•ã ‡§Æ‡•Ç‡§ú‡•Ä ‡§≠‡§®‡•ç‡§® ‡§ö‡§æ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mozgzm</td>\n",
       "      <td>‡§ó‡§æ‡§à‡§≤‡§æ‡§à ‡§ó‡§ß‡§æ ‡§≠‡§®‡•á‡§∞ ‡§¨‡•Ä‡§∞‡§æ‡•á‡§ß ‡§ó‡§∞‡•á‡§ï‡§æ‡•á ‡§õ‡•à‡§® ‡§π‡§æ‡•á‡§≤‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§∞‡•á</td>\n",
       "      <td>NOFF</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                            Comment Label_Binary  \\\n",
       "0  visewu  ‡§≠‡•Ç‡§ï‡§®‡•á ‡§ï‡•Ç‡§ï‡•Ç‡§∞ ‡§≤‡•á ‡§ï‡§π‡•Ä‡§≤‡•á ‡§ü‡•ã‡§ï‡§¶‡•à‡§® ‡§≠‡§®‡•ç‡§õ ‡§π‡•ã ‡§∞‡•à‡§õ ‡§∏‡§æ‡§≤‡§æ ‡§ß...          OFF   \n",
       "1  hgpmyz  ‡§§‡•á‡§∞‡•Ä ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§™‡§∏‡§≤ ‡§Æ‡•Ç‡§ú‡•Ä ‡§ï‡•Ç‡§ï‡•Ç‡§∞‡§ï‡•ã ‡§Æ‡•Ç‡§§ ‡§ñ‡§æ‡§è‡§∏‡•Ä ‡§ú‡•á ‡§™‡§®‡•Ä ‡§∏...          OFF   \n",
       "2  pwqyku  thukka ta machikne valu kun level ko hosh dekh...          OFF   \n",
       "3  voaytw  ‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Ö‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Æ‡•Ç‡§ú‡•Ä‡§π‡§∞‡•ç‡§≤‡§æ‡§à ‡§†‡•Ç‡§ä‡§â‡§â‡§≤‡•ã ‡§Æ‡•Ç‡§ú‡•Ä ‡§≠‡§®‡•ç‡§® ‡§ö‡§æ...          OFF   \n",
       "4  mozgzm     ‡§ó‡§æ‡§à‡§≤‡§æ‡§à ‡§ó‡§ß‡§æ ‡§≠‡§®‡•á‡§∞ ‡§¨‡•Ä‡§∞‡§æ‡•á‡§ß ‡§ó‡§∞‡•á‡§ï‡§æ‡•á ‡§õ‡•à‡§® ‡§π‡§æ‡•á‡§≤‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§∞‡•á         NOFF   \n",
       "\n",
       "  Label_Multiclass  \n",
       "0               OR  \n",
       "1               OO  \n",
       "2               OO  \n",
       "3               OO  \n",
       "4               NO  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "# train_path = \"/kaggle/input/off-dataset/train.json\"\n",
    "# test_path = \"/kaggle/input/off-dataset/test.json\"\n",
    "\n",
    "train_path = r\"D:\\major project\\data\\train_final.json\"\n",
    "test_path = r\"D:\\major project\\nepali-offensive-lang-detection-dataset\\test.json\"\n",
    "\n",
    "train_df = pd.read_json(train_path)\n",
    "test_df = pd.read_json(test_path)\n",
    "\n",
    "\n",
    "# Show basic structure\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"\\nSample data train:\\n\")\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID                                            Comment Label_Binary  \\\n",
      "0  visewu  ‡§≠‡•Ç‡§ï‡§®‡•á ‡§ï‡•Ç‡§ï‡•Ç‡§∞ ‡§≤‡•á ‡§ï‡§π‡•Ä‡§≤‡•á ‡§ü‡•ã‡§ï‡§¶‡•à‡§® ‡§≠‡§®‡•ç‡§õ ‡§π‡•ã ‡§∞‡•à‡§õ ‡§∏‡§æ‡§≤‡§æ ‡§ß...          OFF   \n",
      "1  hgpmyz  ‡§§‡•á‡§∞‡•Ä ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§™‡§∏‡§≤ ‡§Æ‡•Ç‡§ú‡•Ä ‡§ï‡•Ç‡§ï‡•Ç‡§∞‡§ï‡•ã ‡§Æ‡•Ç‡§§ ‡§ñ‡§æ‡§è‡§∏‡•Ä ‡§ú‡•á ‡§™‡§®‡•Ä ‡§∏...          OFF   \n",
      "2  pwqyku  thukka ta machikne valu kun level ko hosh dekh...          OFF   \n",
      "3  voaytw  ‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Ö‡§ó‡•ç‡§Ø‡§æ‡§Å‡§§ ‡§Æ‡•Ç‡§ú‡•Ä‡§π‡§∞‡•ç‡§≤‡§æ‡§à ‡§†‡•Ç‡§ä‡§â‡§â‡§≤‡•ã ‡§Æ‡•Ç‡§ú‡•Ä ‡§≠‡§®‡•ç‡§® ‡§ö‡§æ...          OFF   \n",
      "4  mozgzm     ‡§ó‡§æ‡§à‡§≤‡§æ‡§à ‡§ó‡§ß‡§æ ‡§≠‡§®‡•á‡§∞ ‡§¨‡•Ä‡§∞‡§æ‡•á‡§ß ‡§ó‡§∞‡•á‡§ï‡§æ‡•á ‡§õ‡•à‡§® ‡§π‡§æ‡•á‡§≤‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§∞‡•á         NOFF   \n",
      "\n",
      "  Label_Multiclass  \n",
      "0               OR  \n",
      "1               OO  \n",
      "2               OO  \n",
      "3               OO  \n",
      "4               NO  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:22.337048Z",
     "iopub.status.busy": "2025-07-23T13:31:22.336266Z",
     "iopub.status.idle": "2025-07-23T13:31:22.353679Z",
     "shell.execute_reply": "2025-07-23T13:31:22.352770Z",
     "shell.execute_reply.started": "2025-07-23T13:31:22.337021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New train size: 5577, Validation size: 620, Test size: 1450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create validation set (10‚Äì15% split from train set)\n",
    "# train_df, val_df = train_test_split(\n",
    "#     train_df, test_size=0.15, stratify=train_df[\"Label_Multiclass\"], random_state=42\n",
    "# )\n",
    "val_df = pd.read_json('D:/major project/data/val_final.json')\n",
    "print(f\"\\nNew train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:22.355018Z",
     "iopub.status.busy": "2025-07-23T13:31:22.354649Z",
     "iopub.status.idle": "2025-07-23T13:31:22.365650Z",
     "shell.execute_reply": "2025-07-23T13:31:22.364945Z",
     "shell.execute_reply.started": "2025-07-23T13:31:22.354998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ! pip install gensim==4.3.1\n",
    "# ! pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:22.368209Z",
     "iopub.status.busy": "2025-07-23T13:31:22.367865Z",
     "iopub.status.idle": "2025-07-23T13:31:27.587801Z",
     "shell.execute_reply": "2025-07-23T13:31:27.586904Z",
     "shell.execute_reply.started": "2025-07-23T13:31:22.368186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as regex\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:27.589061Z",
     "iopub.status.busy": "2025-07-23T13:31:27.588688Z",
     "iopub.status.idle": "2025-07-23T13:31:29.895693Z",
     "shell.execute_reply": "2025-07-23T13:31:29.895039Z",
     "shell.execute_reply.started": "2025-07-23T13:31:27.589043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample Preprocessed Outputs:\n",
      "\n",
      "üìù Original       : ‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤\n",
      "üìä ML/GRU Cleaned : bhakhara kagarasa ka dalala\n",
      "ü§ñ XLM-R Input    : ‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†‡•Ä‡§ü‡•Ä ‡§´‡•Ä‡§ü ‡§õ ‡§π‡§æ‡§á‡§ü ‡§§‡•á‡§∞‡•ã ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§™‡§æ‡§≤‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§Ü‡§´‡§®‡•ã ‡§î‡§ï‡§æ‡§§ ‡§π‡•á‡§∞‡•á‡§∞ ‡§∏‡•Ä‡§ü ‡§≤‡•Ä ‡§¨‡•Ç‡§ù‡•Ä‡§∏‡•ç ‡§Ö‡§ù‡•à ‡§Æ‡•Ç‡§ú‡•Ä ‡§à‡§ô‡§≤‡•Ä‡§∏ ‡§õ‡§æ‡§°‡•ç‡§õ\n",
      "üìä ML/GRU Cleaned : phalama halama daI tapaIka Taukala Chakaya bhanana ThaTa phaTa haiTa tara araka pala dakha Aphana aukata harara saTa la bajhasa ajha maja I~Nalasa ChaDaCha\n",
      "ü§ñ XLM-R Input    : ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†‡•Ä‡§ü‡•Ä ‡§´‡•Ä‡§ü ‡§õ ‡§π‡§æ‡§á‡§ü ‡§§‡•á‡§∞‡•ã ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§™‡§æ‡§≤‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§Ü‡§´‡§®‡•ã ‡§î‡§ï‡§æ‡§§ ‡§π‡•á‡§∞‡•á‡§∞ ‡§∏‡•Ä‡§ü ‡§≤‡•Ä ‡§¨‡•Ç‡§ù‡•Ä‡§∏‡•ç ‡§Ö‡§ù‡•à ‡§Æ‡•Ç‡§ú‡•Ä ‡§à‡§ô‡§≤‡•Ä‡§∏ ‡§õ‡§æ‡§°‡•ç‡§õ\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§π‡•à‡§ü ‡§¨‡§ø‡§¶‡•á‡§∏ ‡§Æ‡§æ ‡§®‡§ø ‡§∞‡§æ‡§ú‡§®‡§ø‡§§‡•Ä ‡§™‡§¢‡•á‡§≤‡•á‡§ñ‡•á‡§ï‡§æ ‡§Æ‡§æ‡§®‡•ç‡§õ‡•á ‡§§ ‡§ù‡§® positive ‡§ñ‡§∞‡§æ‡§µ ‡§π‡•Å‡§®‡•ç‡§õ‡•ç‡§® ‡§π‡•ã‡§≤‡§æ ‡§ï‡§ø‡§® ‡§§ ‡§∏‡§π‡§ø‡§≤‡§æ ‡§∏‡•ã‡§ß‡•á‡§∞ ‡§Æ‡§æ‡§∞‡•ç‚Äç‡§Ø‡•ã\n",
      "üìä ML/GRU Cleaned : haTa badasa ma rajanata paDhalakhaka manaCha jhana positive kharava hanaChana hala kana sahala sadhara maraya\n",
      "ü§ñ XLM-R Input    : ‡§π‡•à‡§ü ‡§¨‡§ø‡§¶‡•á‡§∏ ‡§Æ‡§æ ‡§®‡§ø ‡§∞‡§æ‡§ú‡§®‡§ø‡§§‡•Ä ‡§™‡§¢‡•á‡§≤‡•á‡§ñ‡•á‡§ï‡§æ ‡§Æ‡§æ‡§®‡•ç‡§õ‡•á ‡§§ ‡§ù‡§® positive ‡§ñ‡§∞‡§æ‡§µ ‡§π‡•Å‡§®‡•ç‡§õ‡•ç‡§® ‡§π‡•ã‡§≤‡§æ ‡§ï‡§ø‡§® ‡§§ ‡§∏‡§π‡§ø‡§≤‡§æ ‡§∏‡•ã‡§ß‡•á‡§∞ ‡§Æ‡§æ‡§∞‡•ç‚Äç‡§Ø‡•ã\n",
      "------------------------------------------------------------\n",
      "üìù Original       : Thukka mug Randi ho üòà\n",
      "üìä ML/GRU Cleaned : thukka mug randi\n",
      "ü§ñ XLM-R Input    : ‡§†‡•Å‡§ï‡•ç‡§ï ‡§Æ‡•Å‡§ó‡•ç ‡§±‡§®‡•ç‡§¶‡§ø ‡§π‡•ã\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§ß‡§æ‡§Æ‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§∞‡•Ä ‡§¨‡•ã‡§ï‡•ç‡§∏‡•Ä ‡§®‡§ö‡§æ‡§è‡§™‡§õ‡•Ä ‡§ó‡§æ‡§â‡§Å‡§ó‡§æ‡§â‡§Å‡§Æ‡§æ ‡§Ö‡§ù‡•à ‡§™‡§®‡•Ä ‡§ß‡§æ‡§∞‡•ç‡§Æ‡•Ä‡§ï ‡§µ‡•Ä‡§∂‡•ç‡§µ‡§æ‡§∏\n",
      "üìä ML/GRU Cleaned : dhamala yasara bakasa nachaepaCha gaugauma ajha pana dharamaka vashavasa\n",
      "ü§ñ XLM-R Input    : ‡§ß‡§æ‡§Æ‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§∞‡•Ä ‡§¨‡•ã‡§ï‡•ç‡§∏‡•Ä ‡§®‡§ö‡§æ‡§è‡§™‡§õ‡•Ä ‡§ó‡§æ‡§â‡§Å‡§ó‡§æ‡§â‡§Å‡§Æ‡§æ ‡§Ö‡§ù‡•à ‡§™‡§®‡•Ä ‡§ß‡§æ‡§∞‡•ç‡§Æ‡•Ä‡§ï ‡§µ‡•Ä‡§∂‡•ç‡§µ‡§æ‡§∏\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§µ‡§π‡§æ‡§Å ‡§ï‡•ã ‡§Ö‡§∏‡§≤‡•Ä ‡§®‡§æ‡§Æ ‡§â‡§Æ‡•á‡§∂ ‡§¶‡•Ç‡§≤‡§æ‡§≤ ‡§®‡§≠‡§è‡§∞ ‡§â‡§Æ‡•á‡§∂ ‡§ó‡•Ç‡§≤‡§æ‡§≤ ‡§Ø‡§æ ‡§â‡§Æ‡•á‡§∂ ‡§ó‡•Ç‡§≤‡§æ‡§≤ ‡§π‡•ã ‡§∏‡§ú‡•Ä‡§≤‡•ã ‡§ú‡•á ‡§π‡•Ç‡§®‡•ç‡§õ ‡§§‡•á‡§π‡•Ä ‡§≠‡§®‡•å\n",
      "üìä ML/GRU Cleaned : vaha ka asala nama umasha dalala nabhaera umasha galala ya umasha galala ha sajala ja hanaCha taha bhana\n",
      "ü§ñ XLM-R Input    : ‡§µ‡§π‡§æ‡§Å ‡§ï‡•ã ‡§Ö‡§∏‡§≤‡•Ä ‡§®‡§æ‡§Æ ‡§â‡§Æ‡•á‡§∂ ‡§¶‡•Ç‡§≤‡§æ‡§≤ ‡§®‡§≠‡§è‡§∞ ‡§â‡§Æ‡•á‡§∂ ‡§ó‡•Ç‡§≤‡§æ‡§≤ ‡§Ø‡§æ ‡§â‡§Æ‡•á‡§∂ ‡§ó‡•Ç‡§≤‡§æ‡§≤ ‡§π‡•ã ‡§∏‡§ú‡•Ä‡§≤‡•ã ‡§ú‡•á ‡§π‡•Ç‡§®‡•ç‡§õ ‡§§‡•á‡§π‡•Ä ‡§≠‡§®‡•å\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§π‡§æ‡§Æ‡•ç‡§∞‡§æ ‡§Æ‡§Æ‡§§‡§æ‡§Æ‡§π‡•Ä ‡§Ö‡§®‡§®‡•ç‡§§ ‡§™‡•Ç‡§∞‡•ç‡§¨‡§ú ‡§Ü‡§Æ‡§æ ‡§π‡§ú‡•Ç‡§∞‡§Ü‡§Æ‡§æ ‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡§æ‡§∏‡•ç‡§§‡§¨‡•Ä‡§ï ‡§Æ‡•Ç‡§ï‡•ç‡§§‡•Ä‡§¶‡§æ‡§§‡§æ ‡§∂‡•ç‡§∞‡•Ä ‡•©‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú ‡§∞‡§µ‡§ø ‡§ï‡•ã ‡§Ü‡§§‡•ç‡§Æ‡§æ‡§≤‡•á ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä‡§™‡§æ‡§µ‡§∏ ‡§â‡§π‡§æ‡§Å‡§≤‡•á ‡§ó‡§∞‡•ç‡§®‡•Ç ‡§≠‡§è‡§ï‡•ã ‡§∏‡§§‡•Ä‡§™‡•ç‡§∞‡§•‡§æ ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§ï‡•ã ‡§ó‡§π‡•Ä‡§∞‡§æ‡§à ‡§Æ‡§π‡§∂‡•Ç‡§∏ ‡§ó‡§∞‡§æ‡§è‡§ï‡•ã ‡§Æ‡§æ ‡§ù‡•ã‡§≤‡§æ ‡§®‡§æ‡§Æ‡§ï ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§®‡•Ä‡§∞‡•ç‡§Æ‡§æ‡§£‡•ç ‡§ï‡§∞‡•ç‡§§‡§æ ‡§ü‡•Ä‡§Æ‡§≤‡§æ‡§á ‡§ß‡§®‡•ç‡§Ø‡§¨‡§æ‡§¶\n",
      "üìä ML/GRU Cleaned : hamara mamatamaha ananata parabaja Ama hajaraAma haraka basatabaka makatadata shara maharaja rava ka Atamala shanatapavasa uhala garana bhaeka sataparatha anataya ka gaharaI mahashasa garaeka ma jhala namaka phalama naramaNa karata Tamalai dhanayabada\n",
      "ü§ñ XLM-R Input    : ‡§π‡§æ‡§Æ‡•ç‡§∞‡§æ ‡§Æ‡§Æ‡§§‡§æ‡§Æ‡§π‡•Ä ‡§Ö‡§®‡§®‡•ç‡§§ ‡§™‡•Ç‡§∞‡•ç‡§¨‡§ú ‡§Ü‡§Æ‡§æ ‡§π‡§ú‡•Ç‡§∞‡§Ü‡§Æ‡§æ ‡§π‡§∞‡•Ç‡§ï‡•ã ‡§¨‡§æ‡§∏‡•ç‡§§‡§¨‡•Ä‡§ï ‡§Æ‡•Ç‡§ï‡•ç‡§§‡•Ä‡§¶‡§æ‡§§‡§æ ‡§∂‡•ç‡§∞‡•Ä ‡•©‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú ‡§∞‡§µ‡§ø ‡§ï‡•ã ‡§Ü‡§§‡•ç‡§Æ‡§æ‡§≤‡•á ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä‡§™‡§æ‡§µ‡§∏ ‡§â‡§π‡§æ‡§Å‡§≤‡•á ‡§ó‡§∞‡•ç‡§®‡•Ç ‡§≠‡§è‡§ï‡•ã ‡§∏‡§§‡•Ä‡§™‡•ç‡§∞‡§•‡§æ ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§ï‡•ã ‡§ó‡§π‡•Ä‡§∞‡§æ‡§à ‡§Æ‡§π‡§∂‡•Ç‡§∏ ‡§ó‡§∞‡§æ‡§è‡§ï‡•ã ‡§Æ‡§æ ‡§ù‡•ã‡§≤‡§æ ‡§®‡§æ‡§Æ‡§ï ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§®‡•Ä‡§∞‡•ç‡§Æ‡§æ‡§£‡•ç ‡§ï‡§∞‡•ç‡§§‡§æ ‡§ü‡•Ä‡§Æ‡§≤‡§æ‡§á ‡§ß‡§®‡•ç‡§Ø‡§¨‡§æ‡§¶\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§Æ‡§æ‡§°‡•Ä‡§Æ‡§æ ‡§¨‡•Ç‡§ß‡§¨‡§æ‡§∞ ‡§¶‡•Ä‡§â‡§Å‡§∏‡•ã ‡§ú‡§Ç‡§ó‡§≤‡•Ä ‡§π‡§æ‡§§‡•ç‡§§‡•Ä‡§ï‡•ã ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£‡§¨‡§æ‡§ü ‡§Æ‡•É‡§§‡•ç‡§Ø‡•Ç ‡§≠‡§è‡§ï‡§æ ‡§¶‡•Ç‡§à ‡§Æ‡§π‡•Ä‡§≤‡§æ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§µ‡§æ‡§∞‡§≤‡•á ‡§¨‡•Ä‡§π‡•Ä‡§¨‡§æ‡§∞ ‡§∏‡§æ‡§Å‡§ù‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§∂‡§µ ‡§â‡§†‡§æ‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡§∏‡§®‡•ç‡§§‡§æ‡§®‡§≤‡§æ‡§à ‡§∂‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§ó‡•ç‡§Ø‡§æ‡§∞‡•á‡§®‡•ç‡§ü‡•Ä ‡§≠‡§è‡§™‡§õ‡•Ä ‡§™‡•Ä‡§°‡•Ä‡§§ ‡§™‡§∞‡•Ä‡§µ‡§æ‡§∞‡§≤‡•á ‡§∂‡§µ ‡§â‡§†‡§æ‡§è‡§ï‡§æ ‡§π‡•Ç‡§®‡•ç read more gtgtgt\n",
      "üìä ML/GRU Cleaned : maDama badhabara dausa jagala hatataka AkaramaNabaTa mataya bhaeka daI mahalaka paravarala bahabara sajhamatara shava uThaeka Chana sanatanalaI shakaSha rajagaraka gayaranaTa bhaepaCha paData paravarala shava uThaeka hana read more gtgtgt\n",
      "ü§ñ XLM-R Input    : ‡§Æ‡§æ‡§°‡•Ä‡§Æ‡§æ ‡§¨‡•Ç‡§ß‡§¨‡§æ‡§∞ ‡§¶‡•Ä‡§â‡§Å‡§∏‡•ã ‡§ú‡§Ç‡§ó‡§≤‡•Ä ‡§π‡§æ‡§§‡•ç‡§§‡•Ä‡§ï‡•ã ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£‡§¨‡§æ‡§ü ‡§Æ‡•É‡§§‡•ç‡§Ø‡•Ç ‡§≠‡§è‡§ï‡§æ ‡§¶‡•Ç‡§à ‡§Æ‡§π‡•Ä‡§≤‡§æ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§µ‡§æ‡§∞‡§≤‡•á ‡§¨‡•Ä‡§π‡•Ä‡§¨‡§æ‡§∞ ‡§∏‡§æ‡§Å‡§ù‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§∂‡§µ ‡§â‡§†‡§æ‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡§∏‡§®‡•ç‡§§‡§æ‡§®‡§≤‡§æ‡§à ‡§∂‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§ó‡•ç‡§Ø‡§æ‡§∞‡•á‡§®‡•ç‡§ü‡•Ä ‡§≠‡§è‡§™‡§õ‡•Ä ‡§™‡•Ä‡§°‡•Ä‡§§ ‡§™‡§∞‡•Ä‡§µ‡§æ‡§∞‡§≤‡•á ‡§∂‡§µ ‡§â‡§†‡§æ‡§è‡§ï‡§æ ‡§π‡•Ç‡§®‡•ç read more gtgtgt\n",
      "------------------------------------------------------------\n",
      "üìù Original       : tulko gunda lai goli nata gunda lai chai police la salm hanu parxa yea ho desh ko par ani gunda palna pani nata goli han vana pani nata\n",
      "üìä ML/GRU Cleaned : tulko gunda lai goli nata gunda lai chai police la salm hanu parxa yea desh ko par ani gunda palna pani nata goli han vana pani nata\n",
      "ü§ñ XLM-R Input    : ‡§§‡•Å‡§≤‡•ç‡§ï‡•ã ‡§ó‡•Å‡§®‡•ç‡§¶ ‡§≤‡•à ‡§ó‡•ã‡§≤‡§ø ‡§®‡§§ ‡§ó‡•Å‡§®‡•ç‡§¶ ‡§≤‡•à ‡§ö‡•à ‡§™‡•ã‡§≤‡§ø‡§ö‡•á ‡§≤ ‡§∏‡§≤‡•ç‡§Æ‡•ç ‡§π‡§®‡•Å ‡§™‡§∞‡•ç‡§ï‡•ç‡§∑ ‡§Ø‡•á‡§Ö ‡§π‡•ã ‡§¶‡•á‡§∂‡•ç ‡§ï‡•ã ‡§™‡§∞‡•ç ‡§Ö‡§®‡§ø ‡§ó‡•Å‡§®‡•ç‡§¶ ‡§™‡§≤‡•ç‡§® ‡§™‡§®‡§ø ‡§®‡§§ ‡§ó‡•ã‡§≤‡§ø ‡§π‡§®‡•ç ‡§µ‡§® ‡§™‡§®‡§ø ‡§®‡§§\n",
      "------------------------------------------------------------\n",
      "üìù Original       : ‡§∏‡§æ‡§≤‡•á ‡§¶‡•Å‡§¨‡•à ‡§ú‡§æ‡§®‡§æ ‡§∞‡§£‡•ç‡§°‡•Ä‡§ï‡•ã ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§π‡§∞‡•Ç ‡§¨‡§æ‡§ä ‡§¨‡§ø‡§®‡§æ‡§ï‡•ã\n",
      "üìä ML/GRU Cleaned : sala daba jana raNaDaka sanatana hara baU banaka\n",
      "ü§ñ XLM-R Input    : ‡§∏‡§æ‡§≤‡•á ‡§¶‡•Å‡§¨‡•à ‡§ú‡§æ‡§®‡§æ ‡§∞‡§£‡•ç‡§°‡•Ä‡§ï‡•ã ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§π‡§∞‡•Ç ‡§¨‡§æ‡§ä ‡§¨‡§ø‡§®‡§æ‡§ï‡•ã\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Setup ---\n",
    "nepali_stopwords = set([\n",
    "    \"‡§∞\", \"‡§Æ‡§æ\", \"‡§ï‡§ø\", \"‡§≠‡§®‡•á\", \"‡§§\", \"‡§õ\", \"‡§π‡•ã\", \"‡§≤‡§æ‡§à\", \"‡§≤‡•á\",\n",
    "    \"‡§ó‡§∞‡•á‡§ï‡•ã\", \"‡§ó‡§∞‡•ç‡§õ\", \"‡§ó‡§∞‡•ç‡§õ‡§®‡•ç\", \"‡§π‡•Å‡§®‡•ç\", \"‡§ó‡§∞‡•á\", \"‡§®\", \"‡§®‡§≠‡§è‡§ï‡•ã\"\n",
    "])\n",
    "\n",
    "dirghikaran_map = {\n",
    "    # Vowel elongations / replacements (typical dirghikaran)\n",
    "    \"‡§â\": \"‡§ä\",\n",
    "    \"‡§á\": \"‡§à\",\n",
    "    \"‡§ã\": \"‡§∞‡§ø\",  # Often replaced this way in Nepali\n",
    "    \"‡§è\": \"‡§ê\",   # More natural elongated vowel\n",
    "    \"‡§Ö\": \"‡§Ü\",   # If you want to normalize short 'a' to long 'aa'\n",
    "\n",
    "    # Remove zero-width joiner/non-joiner\n",
    "    \"\\u200d\": \"\",\n",
    "    \"\\u200c\": \"\",\n",
    "\n",
    "    # Normalize punctuation marks\n",
    "    \"‡•§\": \".\",\n",
    "    \"‡••\": \".\",\n",
    "\n",
    "    # Common vowel signs normalization (optional)\n",
    "    \"‡§ø\": \"‡•Ä\",\n",
    "    \"‡•Å\": \"‡•Ç\"\n",
    "}\n",
    "\n",
    "\n",
    "roman_stopwords = None  # Will be initialized below\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def is_devanagari(text: str) -> bool:\n",
    "    \"\"\"Detect if text contains any Devanagari characters.\"\"\"\n",
    "    return bool(regex.search(r'\\p{Devanagari}', text))\n",
    "\n",
    "def devanagari_to_roman(text: str) -> str:\n",
    "    try:\n",
    "        return transliterate(text, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def roman_to_devanagari(text: str) -> str:\n",
    "    try:\n",
    "        return transliterate(text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def normalize_dirghikaran(text: str) -> str:\n",
    "    for original, replacement in dirghikaran_map.items():\n",
    "        text = text.replace(original, replacement)\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)         # Remove URLs\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)              # Remove mentions/hashtags\n",
    "    text = re.sub(r\"\\d+\", \"\", text)                    # Remove numbers\n",
    "    text = emoji.replace_emoji(text, replace=\"\")      # Remove emojis\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)                # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()           # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "def clean_text_for_transformer(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove URLs, emojis, and excessive whitespace\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = emoji.replace_emoji(text, replace=\"\")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords_devanagari(text: str) -> str:\n",
    "    \"\"\"Remove Devanagari stopwords from text.\"\"\"\n",
    "    return ' '.join([word for word in text.split() if word not in nepali_stopwords])\n",
    "\n",
    "def remove_stopwords_roman(text: str) -> str:\n",
    "    \"\"\"Remove Romanized stopwords from text.\"\"\"\n",
    "    global roman_stopwords\n",
    "    if roman_stopwords is None:\n",
    "        # Initialize roman_stopwords lazily to avoid dependency issues\n",
    "        roman_stopwords = set([devanagari_to_roman(w) for w in nepali_stopwords])\n",
    "    return ' '.join([word for word in text.split() if word not in roman_stopwords])\n",
    "\n",
    "# --- Preprocessing Pipelines ---\n",
    "\n",
    "def preprocess_for_ml_dl(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess input text for ML/GRU baselines:\n",
    "    - Remove stopwords (script dependent)\n",
    "    - Transliterate Devanagari ‚Üí Roman\n",
    "    - Clean Roman text\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    if is_devanagari(text):\n",
    "        text = clean_text(text)\n",
    "        text = remove_stopwords_devanagari(text)\n",
    "        text = devanagari_to_roman(text)\n",
    "    else:\n",
    "        text = clean_text(text)\n",
    "        text = remove_stopwords_roman(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocess_for_transformer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess input text for Transformer (XLM-Roberta):\n",
    "    - Transliterate Roman ‚Üí Devanagari if needed\n",
    "    - Light cleaning only (no normalization, no punctuation stripping)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    if not is_devanagari(text):\n",
    "        text = roman_to_devanagari(text)\n",
    "\n",
    "    text = clean_text_for_transformer(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# ----------- Apply Preprocessing to Dataset -----------\n",
    "\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    # ML/GRU input: Romanized, cleaned, stopword-removed\n",
    "    df[\"clean_comment\"] = df[\"Comment\"].apply(preprocess_for_ml_dl)\n",
    "    df[\"tokens\"] = df[\"clean_comment\"].apply(str.split)\n",
    "\n",
    "    # Transformer input: Devanagari, normalized, lightly cleaned\n",
    "    df[\"transformer_input\"] = df[\"Comment\"].apply(preprocess_for_transformer)\n",
    "\n",
    "# ----------- Inspect Preprocessing on Samples -----------\n",
    "print(\"üîç Sample Preprocessed Outputs:\\n\")\n",
    "for idx, row in train_df[[\"Comment\", \"clean_comment\", \"transformer_input\"]].head(10).iterrows():\n",
    "    print(f\"üìù Original       : {row['Comment']}\")\n",
    "    print(f\"üìä ML/GRU Cleaned : {row['clean_comment']}\")\n",
    "    print(f\"ü§ñ XLM-R Input    : {row['transformer_input']}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T13:31:29.896592Z",
     "iopub.status.busy": "2025-07-23T13:31:29.896378Z",
     "iopub.status.idle": "2025-07-23T13:31:29.905815Z",
     "shell.execute_reply": "2025-07-23T13:31:29.905169Z",
     "shell.execute_reply.started": "2025-07-23T13:31:29.896575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label_Binary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label_Multiclass",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tokens",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "transformer_input",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "84000593-831a-4fa2-8e9f-8134f758d1b0",
       "rows": [
        [
         "3670",
         "pqlvty",
         "‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤",
         "OFF",
         "OO",
         "bhakhara kagarasa ka dalala",
         "['bhakhara', 'kagarasa', 'ka', 'dalala']",
         "‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤"
        ],
        [
         "3587",
         "dbtslw",
         "‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†‡•Ä‡§ü‡•Ä ‡§´‡•Ä‡§ü ‡§õ ‡§π‡§æ‡§á‡§ü ‡§§‡•á‡§∞‡•ã ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§™‡§æ‡§≤‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§Ü‡§´‡§®‡•ã ‡§î‡§ï‡§æ‡§§ ‡§π‡•á‡§∞‡•á‡§∞ ‡§∏‡•Ä‡§ü ‡§≤‡•Ä ‡§¨‡•Ç‡§ù‡•Ä‡§∏‡•ç ‡§Ö‡§ù‡•à ‡§Æ‡•Ç‡§ú‡•Ä ‡§à‡§ô‡§≤‡•Ä‡§∏ ‡§õ‡§æ‡§°‡•ç‡§õ",
         "OFF",
         "OO",
         "phalama halama daI tapaIka Taukala Chakaya bhanana ThaTa phaTa haiTa tara araka pala dakha Aphana aukata harara saTa la bajhasa ajha maja I~Nalasa ChaDaCha",
         "['phalama', 'halama', 'daI', 'tapaIka', 'Taukala', 'Chakaya', 'bhanana', 'ThaTa', 'phaTa', 'haiTa', 'tara', 'araka', 'pala', 'dakha', 'Aphana', 'aukata', 'harara', 'saTa', 'la', 'bajhasa', 'ajha', 'maja', 'I~Nalasa', 'ChaDaCha']",
         "‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†‡•Ä‡§ü‡•Ä ‡§´‡•Ä‡§ü ‡§õ ‡§π‡§æ‡§á‡§ü ‡§§‡•á‡§∞‡•ã ‡§Ö‡§∞‡•ç‡§ï‡•ã ‡§™‡§æ‡§≤‡•Ä ‡§¶‡•á‡§ñ‡•Ä ‡§Ü‡§´‡§®‡•ã ‡§î‡§ï‡§æ‡§§ ‡§π‡•á‡§∞‡•á‡§∞ ‡§∏‡•Ä‡§ü ‡§≤‡•Ä ‡§¨‡•Ç‡§ù‡•Ä‡§∏‡•ç ‡§Ö‡§ù‡•à ‡§Æ‡•Ç‡§ú‡•Ä ‡§à‡§ô‡§≤‡•Ä‡§∏ ‡§õ‡§æ‡§°‡•ç‡§õ"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label_Binary</th>\n",
       "      <th>Label_Multiclass</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>transformer_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>pqlvty</td>\n",
       "      <td>‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OO</td>\n",
       "      <td>bhakhara kagarasa ka dalala</td>\n",
       "      <td>[bhakhara, kagarasa, ka, dalala]</td>\n",
       "      <td>‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>dbtslw</td>\n",
       "      <td>‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OO</td>\n",
       "      <td>phalama halama daI tapaIka Taukala Chakaya bha...</td>\n",
       "      <td>[phalama, halama, daI, tapaIka, Taukala, Chaka...</td>\n",
       "      <td>‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                            Comment Label_Binary  \\\n",
       "3670  pqlvty                            ‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤          OFF   \n",
       "3587  dbtslw  ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†...          OFF   \n",
       "\n",
       "     Label_Multiclass                                      clean_comment  \\\n",
       "3670               OO                        bhakhara kagarasa ka dalala   \n",
       "3587               OO  phalama halama daI tapaIka Taukala Chakaya bha...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "3670                   [bhakhara, kagarasa, ka, dalala]   \n",
       "3587  [phalama, halama, daI, tapaIka, Taukala, Chaka...   \n",
       "\n",
       "                                      transformer_input  \n",
       "3670                            ‡§≠‡•Ä‡§ñ‡§æ‡§∞‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§ï‡§æ ‡§¶‡§≤‡§æ‡§≤  \n",
       "3587  ‡§´‡•Ä‡§≤‡•ç‡§Æ ‡§π‡§≤‡§Æ‡§æ ‡§¶‡§æ‡§à‡§Ç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã‡§≤‡•á ‡§õ‡•á‡§ï‡•ç‡§Ø‡•ã ‡§≠‡§®‡•ç‡§®‡•á ‡§†...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7927642,
     "sourceId": 12555149,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
